
## Intelligence, Artificial Intelligence (AI)

Intelligence has been defined in many ways: the capacity for abstraction, logic, understanding, self-awareness, learning, emotional knowledge, reasoning, planning, creativity, critical thinking, and problem-solving.

Artificial Intelligence (AI) is a branch of Science which deals with helping machines finding solutions to complex
problems in a more human-like fashion. This generally involves borrowing characteristics from human intelligence,
and applying them as algorithms in a computer friendly way

## AI Perspectives: acting and thinking humanly, acting and thinking rationally 

AI Perspectives: acting humanly

The Turing test, proposed by Alan Turing (1950), was designed as a thought experiment that would sidestep the philosophical vagueness of the question “Can a machine think?” A computer passes the test if a human interrogator,
after posing some written questions, cannot tell whether the written responses come from a person or from a computer.

AI Perspectives: thinking humanly

We can learn about human thought in three ways:

● introspection—trying to catch our own thoughts as they go by;

● psychological experiments—observing a person in action;

● brain imaging—observing the brain in action. Once we have a sufficiently precise theory of the mind, it becomes possible to express the theory as a computer program.

AI Perspectives: thinking rationally

The Greek philosopher Aristotle was one of the first to attempt to codify “right thinking”, their study initiated the field called logic.
Logicians in the 19th century developed a precise notation for statements about objects in the world and the relations among them.

By 1965, programs could, in principle, solve any solvable problem described in logical notation. The so-called logicist tradition within artificial intelligence hopes to build on such programs to create intelligent systems. The theory of probability fills this gap, allowing rigorous reasoning with uncertain information.

AI Perspectives: acting rationally

Agents: An agent is just something that acts. Computer agents are expected to do more: operate autonomously, perceive their environment, persist over a prolonged time period, adapt to change, and create and pursue goals.

Rational Agents: A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome.

AI has focused on the study and construction of agents that do the right thing. What counts as the right thing is defined by the objective that we provide to the agent. This general paradigm is so pervasive that we might call it the standard model. It prevails not only in AI, but also in control theory, where a controller minimizes a cost function; in operations research, where a policy maximizes a sum of rewards; in statistics, where a decision rule minimizes a loss function; and in economics, where a decision maker maximizes utility or some measure of social welfare.

## History of AI

1. The inception of artificial intelligence (1943–1956)
2. Early enthusiasm, great expectations (1952–1969)
3. A dose of reality (1966–1973)
4. Expert systems (1969–1986)
5. The return of neural networks (1986–present)
6. Probabilistic reasoning and machine learning (1987– present)
7. Big data (2001–present)
8. Deep learning (2011–present)

## Foundations of AI: Philosophy, Economics, Psychology, Sociology, Linguistics

1. Philosophy

Blaise Pascal (1623–1662) built the Pascaline in 1642 and wrote that it “produces effects which appear nearer to thought than all the actions of animals.”

Gottfried Wilhelm Leibniz (1646–1716) built a mechanical device intended to carry out operations on concepts rather than numbers, but its scope was rather limited. 

In his 1651 book Leviathan, Thomas Hobbes (1588–1679) suggested the idea of a thinking machine, an “artificial animal” in his words, arguing “For what is the heart but a spring; and the nerves, but so many strings; and the joints, but so many wheels.” He also suggested that reasoning was like numerical computation: “For ‘reason’ ... is nothing but ‘reckoning,’ that is adding and subtracting.”

Aristotle’s algorithm was implemented 2300 years later by Newell and Simon in their General Problem Solver program. We would now call it a greedy regression planning system (see Chapter 11 ). Methods based on logical planning to achieve definite goals dominated the first few decades of theoretical research in AI.

2. Economics

● How should we make decisions in accordance with our preferences?

● How should we do this when others may not go along?

● How should we do this when the payoff may be far in the future?
The science of economics originated in 1776, when Adam Smith (1723–1790) published An Inquiry into the Nature and Causes of the Wealth of Nations.
Léon Walras (pronounced “Valrasse”) (1834–1910) gave utility theory a more general foundation in terms of preferences between gambles on any outcomes (not just monetary outcomes). The theory was improved by Ramsey (1931) and later by John von Neumann and Oskar Morgenstern in their book The Theory of Games and Economic Behavior (1944). Economics is no longer the study of money; rather it is the study of desires and preferences.

Economists, with some exceptions, did not address the third question listed above: how to make rational decisions when payoffs from actions are not immediate but instead result from several actions taken in sequence.

3. Psychology

● How do humans and animals think and act?
The origins of scientific psychology are usually traced to the work of the German physicist Hermann von Helmholtz (1821–1894) and his student Wilhelm Wundt (1832–1920).

In 1879, Wundt opened the first laboratory of experimental psychology, at the University of Leipzig.

Cognitive psychology, which views the brain as an information-processing device, can be traced back at least to the works of William James (1842–1910). Helmholtz also insisted that perception involved a form of unconscious logical inference. The cognitive viewpoint was largely eclipsed by behaviorism in the United States, but at Cambridge’s Applied Psychology Unit, directed by Frederic Bartlett (1886–1969), cognitive modeling was able to flourish.

4. Sociology

Millions of intelligent machines actively participate to social life. They sort and order culture and the social world, by indicating what is “valuable”, “relevant”, “similar”, or “high-risk”. Through their incessant interactions with humans, they powerfully shape society, often in unpredictable ways.

AI technologies are also shaped by society in turn – well beyond developers’ initial choices and intentions. Machine learning systems adjust their future behaviour based on socially-situated feedback loops, and end up replicating the worldviews and biases inscribed in human-generated training data. From a sociological perspective, it can be argued that intelligent machines are not too dissimilar from “regular” social agents: they are socialized thanks to (datafied) learning processes, and practically contribute to the reproduction of material and symbolic inequalities – as in the cases of race and gender discriminations by AI hiring systems, predictive risk models, chatbots, or search engines. In this seminar, I articulate a Bourdieusian understanding of AI systems, aimed to illuminate cultural mechanisms of techno-social reproduction currently obscured by the normative and psychology-centred notion of “bias”.

5. Linguistics

● How does language relate to thought?
In 1957, B. F. Skinner published Verbal Behavior.
the linguist Noam Chomsky, who had just published a book on his own theory, Syntactic Structures.

Modern linguistics and AI, then, were “born” at about the same time, and grew up together, intersecting in a hybrid field called computational linguistics or natural language processing. The problem of understanding language turned out to be considerably more complex than it seemed in 1957. Understanding language requires an understanding of the subject matter and context, not just an understanding of the structure of sentences. This might seem obvious, but it was not widely appreciated until the 1960s.

 Much of the early work in knowledge representation (the study of how to put knowledge into a form that a computer can reason with) was tied to language and informed by research in linguistics, which was connected in turn to decades of work on thephilosophical analysis of language.


## Neuroscience, Mathematics, Computer Science, Control Theory 

1. Neuroscience

● How do brains process information?
Neuroscience is the study of the nervous system, particularly the brain.
Paul Broca’s (1824–1880) investigation of aphasia (speech deficit) in brain-damaged patients in 1861 initiated the study of
the brain’s functional organization by identifying a localized area in the left hemisphere—now called Broca’s area—that is
responsible for speech production.

By that time, it was known that the brain consisted largely of nerve cells, or neurons, but it was not until 1873 that Camillo
Golgi (1843–1926) developed a staining technique allowing the observation of individual neurons (see Figure 1.1 ).
This technique was used by Santiago Ramon y Cajal (1852–1934) in his pioneering studies of neuronal organization. It is now
widely accepted that cognitive functions result from the electrochemical operation of these structures. That is, a collection of
simple cells can lead to thought, action, and consciousness. In the pithy words of John Searle (1992), brains cause minds.

2. Mathematics

●What are the formal rules to draw valid conclusions?

●What can be computed?

●How do we reason with uncertain information?

The idea of formal logic can be traced back to the philosophers of ancient Greece, India, and China, but its
mathematical development really began with the work of George Boole (1815–1864), who worked out the details of
propositional, or Boolean, logic (Boole, 1847).
In 1879, Gottlob Frege (1848–1925) extended Boole’s logic to include objects and relations, creating the first-order
logic that is used today.

Gerolamo Cardano (1501–1576) first framed the idea of probability, describing it in terms of the possible outcomes
of gambling events.

In 1654, Blaise Pascal (1623–1662), in a letter to Pierre Fermat (1601– 1665), showed how to predict the future of an
unfinished gambling game and assign average payoffs to the gamblers.

3. Computer Science

● How can we build an efficient computer?
The first operational computer was the electromechanical Heath Robinson,9 built in 1943 by Alan Turing’s team for
a single purpose: deciphering German messages.

In 1943, the same group developed the Colossus, a powerful general-purpose machine based on vacuum tubes.
The first operational programmable computer was the Z-3, the invention of Konrad Zuse in Germany in 1941. 

The first electronic computer, the ABC, was assembled by John Atanasoff and his student Clifford Berry between 1940
and 1942 at Iowa State University.
We are just beginning to see hardware tuned for AI applications, such as the graphics processing unit (GPU), tensor
processing unit (TPU), and wafer scale engine (WSE).

 From the 1960s to about 2012, the amount of computing
power used to train top machine learning applications followed Moore’s law. A machine learning model that took a
full day to train in 2014 takes only two minutes in 2018 (Ying et al., 2018). Although it is not yet practical,
quantum computing holds out the promise of far greater accelerations for some important subclasses of AI
algorithms.

4. Control Theory

● How can artifacts operate under their own control?
Ktesibios of Alexandria (c. 250 BCE) built the first self-controlling machine: a water clock with a regulator that
maintained a constant flow rate.
Modern control theory, especially the branch known as stochastic optimal control, has as its goal the design of
systems that maximize a cost function over time.
This roughly matches the standard model of AI: designing systems that behave optimally. Why, then, are AI and
control theory two different fields, despite the close connections among their founders? The answer lies in the close
coupling between the mathematical techniques that were familiar to the participants and the corresponding sets of
problems that were encompassed in each world view.

 Calculus and matrix algebra, the tools of control theory, lend
themselves to systems that are describable by fixed sets of continuous variables, whereas AI was founded in part as a
way to escape from these perceived limitations. The tools of logical inference and computation allowed AI
researchers to consider problems such as language, vision, and symbolic planning that fell completely outside the
control theorist’s purview.
##  Applications of AI

1. AI in Astronomy
Artificial Intelligence can be very useful to solve complex universe problems. AI technology can be helpful for understanding the universe such as how it works, origin, etc.

2. AI in Healthcare
In the last, five to ten years, AI becoming more advantageous for the healthcare industry and going to have a significant impact on this industry.
Healthcare Industries are applying AI to make a better and faster diagnosis than humans. AI can help doctors with diagnoses and can inform when patients are worsening so that medical help can reach to the patient before hospitalization.
AD

3. AI in Gaming
AI can be used for gaming purpose. The AI machines can play strategic games like chess, where the machine needs to think of a large number of possible places.

4. AI in Finance
AI and finance industries are the best matches for each other. The finance industry is implementing automation, chatbot, adaptive intelligence, algorithm trading, and machine learning into financial processes.

5. AI in Data Security
The security of data is crucial for every company and cyber-attacks are growing very rapidly in the digital world. AI can be used to make your data more safe and secure. Some examples such as AEG bot, AI2 Platform,are used to determine software bug and cyber-attacks in a better way.

6. AI in Social Media
Social Media sites such as Facebook, Twitter, and Snapchat contain billions of user profiles, which need to be stored and managed in a very efficient way. AI can organize and manage massive amounts of data. AI can analyze lots of data to identify the latest trends, hashtag, and requirement of different users.

7. AI in Travel & Transport
AI is becoming highly demanding for travel industries. AI is capable of doing various travel related works such as from making travel arrangement to suggesting the hotels, flights, and best routes to the customers. Travel industries are using AI-powered chatbots which can make human-like interaction with customers for better and fast response.

8. AI in Automotive Industry
Some Automotive industries are using AI to provide virtual assistant to their user for better performance. Such as Tesla has introduced TeslaBot, an intelligent virtual assistant.
Various Industries are currently working for developing self-driven cars which can make your journey more safe and secure.

9. AI in Robotics:
Artificial Intelligence has a remarkable role in Robotics. Usually, general robots are programmed such that they can perform some repetitive task, but with the help of AI, we can create intelligent robots which can perform tasks with their own experiences without pre-programmed.
Humanoid Robots are best examples for AI in robotics, recently the intelligent Humanoid robot named as Erica and Sophia has been developed which can talk and behave like humans.

10. AI in Entertainment
We are currently using some AI based applications in our daily life with some entertainment services such as Netflix or Amazon. With the help of ML/AI algorithms, these services show the recommendations for programs or shows.